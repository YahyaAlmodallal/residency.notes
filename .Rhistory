labs(title = title, x = x_label, y = y_label) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none")
}
perform_analysis <- function(df, cont_var, cat_var) {
# Ensure there are no zeros or negative values in the continuous variable
df <- df %>%
select(!!sym(cat_var), !!sym(cont_var)) %>%
mutate(!!sym(cont_var) := ifelse(!!sym(cont_var) <= 0, NA, !!sym(cont_var))) %>%
filter(!is.na(!!sym(cont_var))) %>%
mutate(log_transformed = log(!!sym(cont_var)))
# Descriptive statistics on log-transformed data
descriptive_stats <- df %>%
group_by(!!sym(cat_var)) %>%
summarise(
Count_Non_NA = n(),
Real_Mean = exp(mean(log_transformed, na.rm = TRUE)),
sd = exp(sd(log_transformed, na.rm = TRUE)),
N = sum(!is.na(log_transformed)),
sd_log = sd(log_transformed, na.rm = TRUE),
SE = exp(sd_log) / sqrt(N),
ci_lower = exp(mean(log_transformed, na.rm = TRUE) - qt(0.975, df = n() - 1) * sd_log / sqrt(N)),
ci_upper = exp(mean(log_transformed, na.rm = TRUE) + qt(0.975, df = n() - 1) * sd_log / sqrt(N)),
.groups = 'drop'
)
# Filter data for groups that have at least 10 observations
df <- df %>%
group_by(!!sym(cat_var)) %>%
filter(n() >= 10) %>%
ungroup()
# Create formula for ANOVA
anova_formula <- as.formula(paste("log_transformed ~", cat_var))
# Welch's ANOVA on log-transformed data
if (nrow(df) > 10) {
anova_results <- df %>%
welch_anova_test(anova_formula)
}
# Create formula for Games-Howell test
posthoc_formula <- as.formula(paste("log_transformed ~", cat_var))
# Games-Howell post-hoc test on log-transformed data
post_hoc_results <- df %>%
games_howell_test(posthoc_formula)
# Reversing groups and adjusting corresponding values
reversed_post_hoc_results <- post_hoc_results %>%
mutate(
# Swap groups
old_group1 = group1,
group1 = group2,
group2 = old_group1,
# Reverse the signs of estimates and confidence intervals
estimate = -estimate,
old_conf_low = conf.low,
conf.low = -conf.high,
conf.high = -old_conf_low
) %>%
select(-old_group1, -old_conf_low)  # Removing temporary columns
# Combine the original and reversed data frames
combined_results <- bind_rows(post_hoc_results, reversed_post_hoc_results) %>%
distinct
# Merge to add Real Means
combined_results <- combined_results %>%
left_join(descriptive_stats %>% select(!!sym(cat_var), N1 = N, LCI1 = ci_lower, UCI1 = ci_upper, sd1 = sd, se1 = SE, Real_Mean1 = Real_Mean), by = c("group1" = cat_var)) %>%
left_join(descriptive_stats %>% select(!!sym(cat_var), N2 = N, LCI2 = ci_lower, UCI2 = ci_upper, sd2 = sd, se2 = SE, Real_Mean2 = Real_Mean), by = c("group2" = cat_var)) %>%
mutate(
Mean_Difference = Real_Mean2 - Real_Mean1,
Estimated_Real_Mean2 = Real_Mean1 * exp(estimate),
CI_Real_Mean2_Lower = Real_Mean1 * exp(conf.low),
CI_Real_Mean2_Upper = Real_Mean1 * exp(conf.high)
)
return(combined_results)
}
z = sum_df(cons.data)
z
#summarize dataframes
sum_df <- function(df) {
# Create an empty list to store summaries
summary_list <- list()
# 1. Number of rows
summary_list$Number_of_Rows <- nrow(df)
# 2. Names of columns
summary_list$Column_Names <- colnames(df)
# 3. Summaries for character variables with fewer than 100 unique values
char_vars <- df[, sapply(df, is.character)]
if (!is.null(char_vars)) {
summary_list$Character_Variables <- lapply(char_vars, function(x) {
if (length(unique(x)) < 100) {
return(table(x))
} else {
return(NA)  # Or return(NULL) if you prefer not to store anything for columns with >= 100 unique values
}
})
}
# 4. Summaries for numerical variables
num_vars <- df[, sapply(df, is.numeric)]
if (!is.null(num_vars)) {
summary_list$Numerical_Variables <- lapply(num_vars, function(x) {
list(
Median = median(x, na.rm = TRUE) / 60,
IQR_min = IQR(x, na.rm = TRUE) / 60,
Min_min = min(x, na.rm = TRUE) / 60,
Max_min = max(x, na.rm = TRUE) / 60,
log_avg_min = exp(mean(log(x / 60), na.rm = TRUE)),
log_sd_min = exp(sd(log(x / 60), na.rm = TRUE)),
total_day = sum(x, na.rm = TRUE) / (60 * 60 * 24)
)
})
}
# 5. First and last dates for POSIXct variables
date_vars <- df[, sapply(df, function(x) inherits(x, "POSIXct"))]
if (!is.null(date_vars)) {
summary_list$Date_Variables <- lapply(date_vars, function(x) {
list(
First_Date = min(x, na.rm = TRUE),
Last_Date = max(x, na.rm = TRUE)
)
})
}
return(summary_list)
}
# Determine the 'Shift'
get_shift <- function(encounter, editstart) {
hour <- hour(editstart)
if (encounter %in% c("Ambulatory", "HOV", "Telephone Encounter")) {
if (hour >= 7 & hour < 17) {
return("Work-hours")
} else {
return("After work-hours")
}
} else if (encounter == "Emergency Department") {
return(NA)
} else if (encounter %in% "Inpatient") {
if (hour >= 7 & hour < 18) {
return("AM shift")
} else {
return("PM shift")
}
} else {
return(NA)
}
}
# Function to create and save plots for character variables in EDA
create_and_save_plots <- function(data, columns, file_name_prefix, ncol = 3) {
plots <- lapply(columns, function(column) {
ggplot(data, aes(x = !!sym(column))) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), vjust=-0.5) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
})
combined_plot <- do.call(grid.arrange, c(plots, ncol = ncol))
# Save the combined figure
ggsave(paste0(file_name_prefix, "_combined_plot.png"), plot = combined_plot, width = 20, height = 15)
}
# Function to create and save plots for numeric variables in EDA
create_and_save_numeric_plots <- function(data, file_name_prefix, ncol = 3) {
numeric_cols <- data %>%
select_if(is.numeric) %>%
colnames()
plots <- lapply(numeric_cols, function(column) {
hist_plot <- ggplot(data, aes(x = !!sym(column))) +
geom_histogram(bins = 60) +
labs(title = column)
list(hist_plot)
})
plots <- unlist(plots, recursive = FALSE)
# Split plots into groups of 6 and save each group
plot_groups <- split(plots, ceiling(seq_along(plots)/6))
for (i in seq_along(plot_groups)) {
combined_plot <- do.call(grid.arrange, c(plot_groups[[i]], ncol = ncol))
ggsave(paste0(file_name_prefix, "_combined_plot", i, ".png"), plot = combined_plot, width = 20, height = 15)
}
}
# Function to apply transformations, sample means, create plots, and perform tests
analyze_transformations <- function(data, columns, seed = 12) {
test_results <- data.frame(
variable = character(),
transformation = character(),
ad_p_value = numeric(),
shapiro_p_value = numeric(),
stringsAsFactors = FALSE
)
transformations <- list(
original = function(x) x,
log = function(x) ifelse(x > 0, log(x), NA),
sqrt = function(x) ifelse(x >= 0, sqrt(x), NA),
cbrt = function(x) ifelse(x >= 0, x^(1/3), NA),
boxcox = function(x) {
x_positive <- x + 1
lambda <- boxcox(x_positive ~ 1, lambda = seq(-2, 2, by = 0.05))$x[which.max(boxcox(x_positive ~ 1, lambda = seq(-2, 2, by = 0.05))$y)]
(x_positive)^lambda
}
)
for (column in columns) {
for (trans_name in names(transformations)) {
# Apply transformation
trans_data <- data %>% mutate(trans_col = transformations[[trans_name]](!!sym(column)))
# Remove NA values from the transformed data
clean_data <- na.omit(trans_data$trans_col)
if (length(clean_data) >= 500) {  # Ensure there are enough data points for sampling
set.seed(seed)  # for reproducibility
sample_means <- replicate(1000, mean(sample(clean_data, size = 500, replace = TRUE)))
# Create histogram
hist(sample_means, breaks = 60, main = paste("Histogram of Sample Means -", column, trans_name))
# Create QQ plot
qqnorm(sample_means, main = paste("QQ Plot of Sample Means -", column, trans_name))
qqline(sample_means, col = "red")
# Perform tests
ad_test <- ad.test(sample_means)
shapiro_test <- shapiro.test(sample_means)
# Store results
test_results <- rbind(test_results, data.frame(
variable = column,
transformation = trans_name,
ad_p_value = ad_test$p.value,
shapiro_p_value = shapiro_test$p.value
))
} else {
message(paste("Not enough valid data points for", column, "with transformation", trans_name))
}
}
}
return(test_results)
}
# Function to summarize times for each resident in the list of dataframes where each dataframe is the notes of a resident
calculate_statistics <- function(df) {
all_notes <- nrow(df)
inpatient_notes <- sum(df$encountercontext == "Inpatient")
ambulatory_notes <- sum(df$encountercontext == "Ambulatory")
ed_notes <- sum(df$encountercontext == "Emergency Department")
telephone_notes <- sum(df$encountercontext == "Telephone Encounter")
total_time_days <- sum(df$resident.time) / (60 * 60 * 24)
mean_time_mins <- exp(mean(log(df$resident.time / 60), na.rm = TRUE))
sd_time_mins <- exp(sd(log(df$resident.time / 60), na.rm = TRUE))
median_time_mins <- median(df$resident.time / 60)
max_time_mins <- max(df$resident.time / 60)
quantile_25th_time_mins <- quantile(df$resident.time / 60, probs = 0.25)
quantile_75th_time_mins <- quantile(df$resident.time / 60, probs = 0.75)
weekend_time_days <- sum(df$weekend) / (60 * 60 * 24)
percentage_weekend <- sum(df$weekend) / sum(df$resident.time) * 100
pm_time_days <- sum(df$pm, na.rm = TRUE) / (60 * 60 * 24)
percentage_pm <- sum(df$pm, na.rm = TRUE) / sum(df$resident.time) * 100
after_hours_time_days <- sum(df$after.hours, na.rm = TRUE) / (60 * 60 * 24)
percentage_after_hours <- sum(df$after.hours, na.rm = TRUE) / sum(df$resident.time) * 100
mean_note_size <- exp(mean(log(df$notesize), na.rm = TRUE))
sd_note_size <- exp(sd(log(df$notesize), na.rm = TRUE))
count_dictated <- sum(df$`%voice` > 0, na.rm = TRUE)
mean_dictation <- mean(df$`%voice`, na.rm = TRUE)
sd_dictation <- sd(df$`%voice`, na.rm = TRUE)
count_copied <- sum(df$`%copied` > 0, na.rm = TRUE)
mean_copied <- mean(df$`%copied`, na.rm = TRUE)
sd_copied <- sd(df$`%copied`, na.rm = TRUE)
# Specific mean times calculations with exponential and log transformation
mean_hp <- ifelse(any(df$notetype == "H&P"), exp(mean(log(df$resident.time[df$notetype == "H&P"] / 60), na.rm = TRUE)), NA)
mean_CN <- ifelse(any(df$notetype == "Clinic Note"), exp(mean(log(df$resident.time[df$notetype == "Clinic Note"] / 60), na.rm = TRUE)), NA)
mean_DS <- ifelse(any(df$notetype == "Discharge Summary"), exp(mean(log(df$resident.time[df$notetype == "Discharge Summary"] / 60), na.rm = TRUE)), NA)
mean_Cs <- ifelse(any(df$notetype == "Consults"), exp(mean(log(df$resident.time[df$notetype == "Consults"] / 60), na.rm = TRUE)), NA)
mean_PN <- ifelse(any(df$notetype == "Progress Notes"), exp(mean(log(df$resident.time[df$notetype == "Progress Notes"] / 60), na.rm = TRUE)), NA)
mean_TE <- ifelse(any(df$notetype == "Telephone Encounter"), exp(mean(log(df$resident.time[df$notetype == "Telephone Encounter"] / 60), na.rm = TRUE)), NA)
mean_ED <- ifelse(any(df$notetype == "Emergency Department"), exp(mean(log(df$resident.time[df$notetype == "Emergency Department"] / 60), na.rm = TRUE)), NA)
mean_P <- ifelse(any(df$notetype == "Procedures"), exp(mean(log(df$resident.time[df$notetype == "Procedures"] / 60), na.rm = TRUE)), NA)
smartphrase_mean <- mean(lengths(gregexpr("\\[", df$smartphraseids)), na.rm = TRUE)
time_to_complete_mean <- exp(mean(log(df$starttostop), na.rm = TRUE)) / 60 * 24
time_to_complete_sd <- exp(sd(log(df$starttostop), na.rm = TRUE))
number_copied_forward <- sum(df$iteration > 0, na.rm = TRUE)
mean_iteration <- mean(df$iteration, na.rm = TRUE)
sd_iteration <- sd(df$iteration, na.rm = TRUE)
# Create a dataframe of the computed values
data.frame(
'All.Notes' = all_notes,
'Inpatient' = inpatient_notes,
'Ambulatory' = ambulatory_notes,
EDNotes = ed_notes,
TelephoneNotes = telephone_notes,
TotalTimeDays = total_time_days,
Overall = mean_time_mins,
SDTimeMins = sd_time_mins,
MedianTimeMins = median_time_mins,
MaxTimeMins = max_time_mins,
IQR25th = quantile_25th_time_mins,
IQR75th = quantile_75th_time_mins,
WeekendTimeDays = weekend_time_days,
Weekend = percentage_weekend,
PMTimeDays = pm_time_days,
'Inpatient.PM' = percentage_pm,
AfterHoursTimeDays = after_hours_time_days,
'Ambulatory.After_Hours' = percentage_after_hours,
'Note.Size' = mean_note_size,
SDNoteSize = sd_note_size,
CountDictated = count_dictated,
'Percent.Dictated' = mean_dictation,
SDDictation = sd_dictation,
CountCopied = count_copied,
'Percent.Copied' = mean_copied,
SDCopied = sd_copied,
SmartphraseMean = smartphrase_mean,
'Days.to.Sign' = time_to_complete_mean,
TimeToCompleteSD = time_to_complete_sd,
NumberCopiedForward = number_copied_forward,
MeanIteration = mean_iteration,
SDIteration = sd_iteration,
'HP' = mean_hp,
'Clinic' = mean_CN,
'Discharge' = mean_DS,
'Consult' = mean_Cs,
'Progress' = mean_PN,
'Telephone' = mean_TE,
'ED' = mean_ED,
'Procedure' = mean_P
)
}
# Function to melt and create plots for specific variable groups without legend
create_melted_plot <- function(data, columns, title, x_label, y_label) {
melted_data <- melt(data[, c("PGY", columns)], id.vars = "PGY")
ggplot(melted_data, aes(x = variable, y = value, color = PGY)) +
geom_point(position = position_jitter(width = 0.2, height = 0)) +
labs(title = title, x = x_label, y = y_label) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none")
}
perform_analysis <- function(df, cont_var, cat_var) {
# Ensure there are no zeros or negative values in the continuous variable
df <- df %>%
select(!!sym(cat_var), !!sym(cont_var)) %>%
mutate(!!sym(cont_var) := ifelse(!!sym(cont_var) <= 0, NA, !!sym(cont_var))) %>%
filter(!is.na(!!sym(cont_var))) %>%
mutate(log_transformed = log(!!sym(cont_var)))
# Descriptive statistics on log-transformed data
descriptive_stats <- df %>%
group_by(!!sym(cat_var)) %>%
summarise(
Count_Non_NA = n(),
Real_Mean = exp(mean(log_transformed, na.rm = TRUE)),
sd = exp(sd(log_transformed, na.rm = TRUE)),
N = sum(!is.na(log_transformed)),
sd_log = sd(log_transformed, na.rm = TRUE),
SE = exp(sd_log) / sqrt(N),
ci_lower = exp(mean(log_transformed, na.rm = TRUE) - qt(0.975, df = n() - 1) * sd_log / sqrt(N)),
ci_upper = exp(mean(log_transformed, na.rm = TRUE) + qt(0.975, df = n() - 1) * sd_log / sqrt(N)),
.groups = 'drop'
)
# Filter data for groups that have at least 10 observations
df <- df %>%
group_by(!!sym(cat_var)) %>%
filter(n() >= 10) %>%
ungroup()
# Create formula for ANOVA
anova_formula <- as.formula(paste("log_transformed ~", cat_var))
# Welch's ANOVA on log-transformed data
if (nrow(df) > 10) {
anova_results <- df %>%
welch_anova_test(anova_formula)
}
# Create formula for Games-Howell test
posthoc_formula <- as.formula(paste("log_transformed ~", cat_var))
# Games-Howell post-hoc test on log-transformed data
post_hoc_results <- df %>%
games_howell_test(posthoc_formula)
# Reversing groups and adjusting corresponding values
reversed_post_hoc_results <- post_hoc_results %>%
mutate(
# Swap groups
old_group1 = group1,
group1 = group2,
group2 = old_group1,
# Reverse the signs of estimates and confidence intervals
estimate = -estimate,
old_conf_low = conf.low,
conf.low = -conf.high,
conf.high = -old_conf_low
) %>%
select(-old_group1, -old_conf_low)  # Removing temporary columns
# Combine the original and reversed data frames
combined_results <- bind_rows(post_hoc_results, reversed_post_hoc_results) %>%
distinct
# Merge to add Real Means
combined_results <- combined_results %>%
left_join(descriptive_stats %>% select(!!sym(cat_var), N1 = N, LCI1 = ci_lower, UCI1 = ci_upper, sd1 = sd, se1 = SE, Real_Mean1 = Real_Mean), by = c("group1" = cat_var)) %>%
left_join(descriptive_stats %>% select(!!sym(cat_var), N2 = N, LCI2 = ci_lower, UCI2 = ci_upper, sd2 = sd, se2 = SE, Real_Mean2 = Real_Mean), by = c("group2" = cat_var)) %>%
mutate(
Mean_Difference = Real_Mean2 - Real_Mean1,
Estimated_Real_Mean2 = Real_Mean1 * exp(estimate),
CI_Real_Mean2_Lower = Real_Mean1 * exp(conf.low),
CI_Real_Mean2_Upper = Real_Mean1 * exp(conf.high)
)
return(combined_results)
}
# Specify file paths
raw_files <- c(
"C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Raw files\\AllNotes124624_20240707_1002.xlsx",
"C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Raw files\\AllNotes721622_20240623_1717.xlsx",
"C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Raw files\\AllNotes722623_20240623_1715.xlsx",
"C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Raw files\\AllNotes7231223_20240623_1719.xlsx"
)
# Read each file and combine rows
all_data_1 <- suppressWarnings(
lapply(raw_files, read_excel) %>%
bind_rows()
)
# Names of all residents over the last 3 years, per year. Names have changed to some extent overtime, the names in the above uploaded files will be adjusted to match the ones in this file
resident.names <- read.csv("C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Edited files\\All Residents 21-24.csv")
# Or if you want to convert them to a vector
res_vector <- unlist(resident.names)
# The true service of all attendings, inspired by earlier work and updated in 7/2024
true.service <- read_xlsx("C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Edited files\\true.author.service.7.24.xlsx")
# Filter rows where 'authortype' is 'attending'
staffs <- true.service %>%
filter(authortype == "attending") %>%
pull(name)
# Convert all column names to lowercase and remove spaces
names(all_data_1) <- tolower(gsub("[ '?]", "", names(all_data_1)))
u = sum_df(all_data_1)
# Refining: rename columns, column class, nnsy service, delete columns
all_data_1 <- all_data_1 %>%
rename(
specialtyatnote = `specialty...19`,
specialtycurrent = `specialty...20`
) %>%
mutate(
# Edit column class, remove % symbol
`%voice` = as.numeric(gsub("%", "", `%voice`)),
`%copied` = as.numeric(gsub("%", "", `%copied`)),
noteid = as.character(noteid),
# Recategorize 'authortype'
authortype = case_when(
authortype %in% c("(Other)", "Clerk", "Dietitian", "Medical Student", "Non-Privileged Provider", "Nurse-ARNP", "Nursing Assistant", "Pharmacist", "Physician-Fellow", "Dentist-Resident", "Medical Assistant", "Occupational Therapist", "PA Student", "Physical Therapist", "Speech Pathologist", "Student Nurse", "Physician Assistant", "Registered Nurse", "Social Worker") ~ "other",
authortype %in% c("Anesthesiologist", "Physician-Associate", "Physician-Fellow Associate", "Physician-Staff", "Physician-Visit Assistant Prof", "Physician-Visit Associate") ~ "attending",
authortype == "Physician-Resident" ~ "resident",
TRUE ~ authortype # Preserve original for undefined categories
)
) %>%
# Set encountercontext for specific notetypes
mutate(encountercontext = case_when(
notetype %in% c("Clinic Note", "Clinical Letter") ~ "Ambulatory",
notetype %in% c("Discharge Summary", "H&P", "Interim Progress Note", "Progress Notes") ~ "Inpatient",
notetype %in% c("ED Provider Notes", "ED Notes") ~ "Emergency Department",
notetype %in% c("Telephone Encounter") ~ "Telephone Encounter",
TRUE ~ encountercontext
)) %>%
mutate(authorsservice = case_when(
authorsservice %in% c("Pediatrics", "QuickCare") ~ "PED General",
authorsservice == "Psychiatry" ~ "PSY Child Psychiatry",
authorsservice == "MED Allergy/Immunology" ~ "PED Allergy/Immunology",
TRUE ~ authorsservice
)) %>%
mutate(notetype = case_when(
notetype %in% c("ED Provider Notes", "ED Notes") ~ "Emergency Department",
TRUE ~ notetype
)) %>%
# Change encountercontext values of "HOV"
mutate(encountercontext = if_else(encountercontext == "HOV", "Ambulatory", encountercontext)) %>%
# Set authorsservice for Emergency Department
mutate(authorsservice = if_else(encountercontext == "Emergency Department", "Emergency Department", authorsservice)) %>%
# Update encountercontext for specific services
mutate(encountercontext = case_when(
(encountercontext %in% c("Ambulatory", "Inpatient") & authorsservice == "Emergency Department") ~ "Emergency Department",
TRUE ~ encountercontext
))%>%
# Remove unneeded columns
select(-noteactive, -`%***`)
# summary.1: raw data after some refining
summary.1 <- sum_df(all_data_1)
# Identifying notes with equal number of authors and edit times, excluding notes with unequal numbers, and identifying notes with no time data
# available and equal edit times and author information
all_data_2 <- all_data_1 %>%
mutate(
authorcount = str_count(author, "\n") + 1,
timecount = str_count(`edittime(seconds)`, "\n") + 1,
) %>%
filter(authorcount == timecount) %>%
select(-authorcount, -timecount)
# not equal number (too many edit instances)
not_equal <- all_data_1 %>%
mutate(
authorcount = str_count(author, "\n") + 1,
timecount = str_count(`edittime(seconds)`, "\n") + 1
) %>%
filter(authorcount != timecount) %>%
select(-authorcount, -timecount)
# not available edit time information
combined <- bind_rows(not_equal, all_data_2)
no_times <- anti_join(all_data_1, combined, by = "noteid")
all_exported_count = nrow(all_data_1)
after_deleteing_incomplete_data_count = nrow(all_data_2)
inequal_number_count = nrow(not_equal)
no_time_data_count = nrow(no_times)
print(nrow(all_data_1))
print(nrow(all_data_2))
print(nrow(not_equal))
print(nrow(no_times))
# The edit start and edit stop dates are not uniform, there were about 3000 values where the dates are shown as serial numbers, luckily these are easy to extract since each has a single editing instance
# Extract serial number dates and convert them back to actual dates, then calculate the time between the start and end of each note
filtered_data <- all_data_2 %>%
filter(grepl("^[0-9]+\\.?[0-9]*$", editstart), grepl("^[0-9]+\\.?[0-9]*$", editstop)) %>%
mutate(
editstart = as.POSIXct(as.Date(as.numeric(editstart), origin = "1899-12-30"), tz = "UTC"),
editstop = as.POSIXct(as.Date(as.numeric(editstop), origin = "1899-12-30"), tz = "UTC"),
starttostop = difftime(editstop, editstart, units = "hours"),
`edittime(seconds)` = as.numeric(`edittime(seconds)`)
)
# Remaining rows, to calculate the time between the start and end of these notes; will need to divide the contents of each row, convert them to date/time, then calculate the difference
# Step 1: Filter out rows in all_data_2 that match rows in filtered_data
all_data_2_remaining <- all_data_2 %>%
anti_join(filtered_data, by = "noteid") %>%
mutate(
first_editstart = sapply(strsplit(as.character(editstart), "\r\n"), `[`, 1),
last_editstop = sapply(strsplit(as.character(editstop), "\r\n"), tail, 1),
first_editstart = as.POSIXct(first_editstart, format = "%m/%d/%Y %I:%M:%S %p", tz = "UTC"),
last_editstop = as.POSIXct(last_editstop, format = "%m/%d/%Y %I:%M:%S %p", tz = "UTC"),
starttostop = difftime(last_editstop, first_editstart, units = "hours")
) %>%
select(-last_editstop, -first_editstart)
