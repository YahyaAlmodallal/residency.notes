library(purrr)
library(report)
library(grid)
library(stringr)
library(gridExtra)
library(MASS)
library(knitr)
library(tools)
library(kableExtra)
library(DT)
library(broom)
library(htmlwidgets)
library(webshot)
library(extrafont)
library(ragg)
library(plotly)
library(pagedown)
library(readxl)
library(rlang)
library(nortest)
library(glue)
library(reshape2)
library(GGally)
library(boot)
conflict_prefer("select", "dplyr")
conflicts_prefer(dplyr::filter)  # Set conflict resolution preferences
#summarize dataframes
sum_df <- function(df) {
# Create an empty list to store summaries
summary_list <- list()
# 1. Number of rows
summary_list$Number_of_Rows <- nrow(df)
# 2. Names of columns
summary_list$Column_Names <- colnames(df)
# 3. Summaries for character variables with fewer than 100 unique values
char_vars <- df[, sapply(df, is.character)]
if (!is.null(char_vars)) {
summary_list$Character_Variables <- lapply(char_vars, function(x) {
if (length(unique(x)) < 100) {
return(table(x))
} else {
return(NA)  # Or return(NULL) if you prefer not to store anything for columns with >= 100 unique values
}
})
}
# 4. Summaries for numerical variables
num_vars <- df[, sapply(df, is.numeric)]
if (!is.null(num_vars)) {
summary_list$Numerical_Variables <- lapply(num_vars, function(x) {
list(
Median = median(x, na.rm = TRUE),
IQR = IQR(x, na.rm = TRUE),
Min = min(x, na.rm = TRUE),
Max = max(x, na.rm = TRUE)
)
})
}
# 5. First and last dates for POSIXct variables
date_vars <- df[, sapply(df, function(x) inherits(x, "POSIXct"))]
if (!is.null(date_vars)) {
summary_list$Date_Variables <- lapply(date_vars, function(x) {
list(
First_Date = min(x, na.rm = TRUE),
Last_Date = max(x, na.rm = TRUE)
)
})
}
return(summary_list)
}
# Determine the 'Shift'
get_shift <- function(encounter, editstart) {
hour <- hour(editstart)
if (encounter %in% c("Ambulatory", "HOV", "Telephone Encounter")) {
if (hour >= 7 & hour < 17) {
return("Work-hours")
} else {
return("After work-hours")
}
} else if (encounter == "Emergency Department") {
return(NA)
} else if (encounter %in% "Inpatient") {
if (hour >= 7 & hour < 18) {
return("AM shift")
} else {
return("PM shift")
}
} else {
return(NA)
}
}
# Function to create and save plots for character variables in EDA
create_and_save_plots <- function(data, columns, file_name_prefix, ncol = 3) {
plots <- lapply(columns, function(column) {
ggplot(data, aes(x = !!sym(column))) +
geom_bar() +
geom_text(stat='count', aes(label=..count..), vjust=-0.5) +
theme(axis.text.x = element_text(angle = 90, hjust = 1))
})
combined_plot <- do.call(grid.arrange, c(plots, ncol = ncol))
# Save the combined figure
ggsave(paste0(file_name_prefix, "_combined_plot.png"), plot = combined_plot, width = 20, height = 15)
}
# Function to create and save plots for numeric variables in EDA
create_and_save_numeric_plots <- function(data, file_name_prefix, ncol = 3) {
numeric_cols <- data %>%
select_if(is.numeric) %>%
colnames()
plots <- lapply(numeric_cols, function(column) {
hist_plot <- ggplot(data, aes(x = !!sym(column))) +
geom_histogram(bins = 60) +
labs(title = column)
list(hist_plot)
})
plots <- unlist(plots, recursive = FALSE)
# Split plots into groups of 6 and save each group
plot_groups <- split(plots, ceiling(seq_along(plots)/6))
for (i in seq_along(plot_groups)) {
combined_plot <- do.call(grid.arrange, c(plot_groups[[i]], ncol = ncol))
ggsave(paste0(file_name_prefix, "_combined_plot", i, ".png"), plot = combined_plot, width = 20, height = 15)
}
}
# Function to apply transformations, sample means, create plots, and perform tests
analyze_transformations <- function(data, columns, seed = 12) {
test_results <- data.frame(
variable = character(),
transformation = character(),
ad_p_value = numeric(),
shapiro_p_value = numeric(),
stringsAsFactors = FALSE
)
transformations <- list(
original = function(x) x,
log = function(x) ifelse(x > 0, log(x), NA),
sqrt = function(x) ifelse(x >= 0, sqrt(x), NA),
cbrt = function(x) ifelse(x >= 0, x^(1/3), NA),
boxcox = function(x) {
x_positive <- x + 1
lambda <- boxcox(x_positive ~ 1, lambda = seq(-2, 2, by = 0.05))$x[which.max(boxcox(x_positive ~ 1, lambda = seq(-2, 2, by = 0.05))$y)]
(x_positive)^lambda
}
)
for (column in columns) {
for (trans_name in names(transformations)) {
# Apply transformation
trans_data <- data %>% mutate(trans_col = transformations[[trans_name]](!!sym(column)))
# Remove NA values from the transformed data
clean_data <- na.omit(trans_data$trans_col)
if (length(clean_data) >= 500) {  # Ensure there are enough data points for sampling
set.seed(seed)  # for reproducibility
sample_means <- replicate(1000, mean(sample(clean_data, size = 500, replace = TRUE)))
# Create histogram
hist(sample_means, breaks = 60, main = paste("Histogram of Sample Means -", column, trans_name))
# Create QQ plot
qqnorm(sample_means, main = paste("QQ Plot of Sample Means -", column, trans_name))
qqline(sample_means, col = "red")
# Perform tests
ad_test <- ad.test(sample_means)
shapiro_test <- shapiro.test(sample_means)
# Store results
test_results <- rbind(test_results, data.frame(
variable = column,
transformation = trans_name,
ad_p_value = ad_test$p.value,
shapiro_p_value = shapiro_test$p.value
))
} else {
message(paste("Not enough valid data points for", column, "with transformation", trans_name))
}
}
}
return(test_results)
}
# Function to summarize times for each resident in the list of dataframes where each dataframe is the notes of a resident
calculate_statistics <- function(df) {
all_notes <- nrow(df)
inpatient_notes <- sum(df$encountercontext == "Inpatient")
ambulatory_notes <- sum(df$encountercontext == "Ambulatory")
ed_notes <- sum(df$encountercontext == "Emergency Department")
telephone_notes <- sum(df$encountercontext == "Telephone Encounter")
total_time_days <- sum(df$resident.time) / (60 * 60 * 24)
mean_time_mins <- exp(mean(log(df$resident.time / 60), na.rm = TRUE))
sd_time_mins <- exp(sd(log(df$resident.time / 60), na.rm = TRUE))
median_time_mins <- median(df$resident.time / 60)
max_time_mins <- max(df$resident.time / 60)
quantile_25th_time_mins <- quantile(df$resident.time / 60, probs = 0.25)
quantile_75th_time_mins <- quantile(df$resident.time / 60, probs = 0.75)
weekend_time_days <- sum(df$weekend) / (60 * 60 * 24)
percentage_weekend <- sum(df$weekend) / sum(df$resident.time) * 100
pm_time_days <- sum(df$pm) / (60 * 60 * 24)
percentage_pm <- sum(df$pm) / sum(df$resident.time) * 100
after_hours_time_days <- sum(df$after.hours) / (60 * 60 * 24)
percentage_after_hours <- sum(df$after.hours) / sum(df$resident.time) * 100
mean_note_size <- exp(mean(log(df$notesize), na.rm = TRUE))
sd_note_size <- exp(sd(log(df$notesize), na.rm = TRUE))
count_dictated <- sum(df$`%voice` > 0, na.rm = TRUE)
mean_dictation <- mean(df$`%voice`, na.rm = TRUE)
sd_dictation <- sd(df$`%voice`, na.rm = TRUE)
count_copied <- sum(df$`%copied` > 0, na.rm = TRUE)
mean_copied <- mean(df$`%copied`, na.rm = TRUE)
sd_copied <- sd(df$`%copied`, na.rm = TRUE)
# Specific mean times calculations with exponential and log transformation
mean_hp <- ifelse(any(df$notetype == "H&P"), exp(mean(log(df$resident.time[df$notetype == "H&P"] / 60), na.rm = TRUE)), NA)
mean_CN <- ifelse(any(df$notetype == "Clinic Note"), exp(mean(log(df$resident.time[df$notetype == "Clinic Note"] / 60), na.rm = TRUE)), NA)
mean_DS <- ifelse(any(df$notetype == "Discharge Summary"), exp(mean(log(df$resident.time[df$notetype == "Discharge Summary"] / 60), na.rm = TRUE)), NA)
mean_Cs <- ifelse(any(df$notetype == "Consults"), exp(mean(log(df$resident.time[df$notetype == "Consults"] / 60), na.rm = TRUE)), NA)
mean_PN <- ifelse(any(df$notetype == "Progress Notes"), exp(mean(log(df$resident.time[df$notetype == "Progress Notes"] / 60), na.rm = TRUE)), NA)
mean_TE <- ifelse(any(df$notetype == "Telephone Encounter"), exp(mean(log(df$resident.time[df$notetype == "Telephone Encounter"] / 60), na.rm = TRUE)), NA)
mean_ED <- ifelse(any(df$notetype == "Emergency Department"), exp(mean(log(df$resident.time[df$notetype == "Emergency Department"] / 60), na.rm = TRUE)), NA)
mean_P <- ifelse(any(df$notetype == "Procedures"), exp(mean(log(df$resident.time[df$notetype == "Procedures"] / 60), na.rm = TRUE)), NA)
smartphrase_mean <- mean(lengths(gregexpr("\\[", df$smartphraseids)), na.rm = TRUE)
time_to_complete_mean <- exp(mean(log(df$starttostop), na.rm = TRUE)) / 60 * 24
time_to_complete_sd <- exp(sd(log(df$starttostop), na.rm = TRUE))
number_copied_forward <- sum(df$iteration > 0, na.rm = TRUE)
mean_iteration <- mean(df$iteration, na.rm = TRUE)
sd_iteration <- sd(df$iteration, na.rm = TRUE)
# Create a dataframe of the computed values
data.frame(
'All.Notes' = all_notes,
'Inpatient' = inpatient_notes,
'Ambulatory' = ambulatory_notes,
EDNotes = ed_notes,
TelephoneNotes = telephone_notes,
TotalTimeDays = total_time_days,
Overall = mean_time_mins,
SDTimeMins = sd_time_mins,
MedianTimeMins = median_time_mins,
MaxTimeMins = max_time_mins,
IQR25th = quantile_25th_time_mins,
IQR75th = quantile_75th_time_mins,
WeekendTimeDays = weekend_time_days,
Weekend = percentage_weekend,
PMTimeDays = pm_time_days,
'Inpatient.PM' = percentage_pm,
AfterHoursTimeDays = after_hours_time_days,
'Ambulatory.After_Hours' = percentage_after_hours,
'Note.Size' = mean_note_size,
SDNoteSize = sd_note_size,
CountDictated = count_dictated,
'Percent.Dictated' = mean_dictation,
SDDictation = sd_dictation,
CountCopied = count_copied,
'Percent.Copied' = mean_copied,
SDCopied = sd_copied,
SmartphraseMean = smartphrase_mean,
'Days.to.Sign' = time_to_complete_mean,
TimeToCompleteSD = time_to_complete_sd,
NumberCopiedForward = number_copied_forward,
MeanIteration = mean_iteration,
SDIteration = sd_iteration,
'HP' = mean_hp,
'Clinic' = mean_CN,
'Discharge' = mean_DS,
'Consult' = mean_Cs,
'Progress' = mean_PN,
'Telephone' = mean_TE,
'ED' = mean_ED,
'Procedure' = mean_P
)
}
# Function to melt and create plots for specific variable groups without legend
create_melted_plot <- function(data, columns, title, x_label, y_label) {
melted_data <- melt(data[, c("PGY", columns)], id.vars = "PGY")
ggplot(melted_data, aes(x = variable, y = value, color = PGY)) +
geom_point(position = position_jitter(width = 0.2, height = 0)) +
labs(title = title, x = x_label, y = y_label) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
legend.position = "none")
}
run_individual_regressions <- function(data, response_var, predictors) {
results <- list()  # To store model summaries
# Loop through each predictor and fit a linear model
for (pred in predictors) {
formula <- as.formula(paste(response_var, "~", pred))  # Construct the formula
model <- lm(formula, data = data)
summary_model <- summary(model)  # Summarize the model
results[[pred]] <- summary_model  # Store the summary in the list
}
return(results)
}
# List of predictors
predictors_list <- c("`%copied`", "`%voice`", "smart_phrases_count", "weekend", "pm", "notesize",
"resident.time", "staff.time", "iteration", "starttostop", "sources", "resident.percent")
# Running the function for 'total.time'
model_results <- run_individual_regressions(cons.data, "total.time", predictors_list)
cons.data <- readRDS("cons_data.rds")
# Applying log transformation to the predictors
cons.data <- cons.data %>%
mutate_at(vars(`%copied`, `%voice`, smart_phrases_count, weekend, pm, notesize,
resident.time, staff.time, iteration, starttostop, sources, resident.percent),
~ log1p(.))  # log1p is used to apply log(1 + x) to avoid log(0)
cons.data <- readRDS("cons_data.rds")
# Calculate the logarithm of total time
cons.data <- cons.data %>%
mutate(smart_phrases_count = str_count(smartphraseids, "\\["))  # Count "[" in smartphraseids
# Applying log transformation to the predictors
cons.data <- cons.data %>%
mutate_at(vars(`%copied`, `%voice`, smart_phrases_count, weekend, pm, notesize,
resident.time, staff.time, iteration, starttostop, sources, resident.percent),
~ log1p(.))  # log1p is used to apply log(1 + x) to avoid log(0)
# Select relevant columns
selected_data <- cons.data %>%
select(log_total_time, `%copied`, `%voice`, smart_phrases_count, weekend,
pm, notesize, resident.time, staff.time, iteration, starttostop,
sources, resident.percent)
# List of predictors
predictors_list <- c("`%copied`", "`%voice`", "smart_phrases_count", "weekend", "pm", "notesize",
"resident.time", "staff.time", "iteration", "starttostop", "sources", "resident.percent")
# Running the function for 'total.time'
model_results <- run_individual_regressions(cons.data, "total.time", predictors_list)
model_results[["`%copied`"]]
View(model_results)
View(model_results)
model_results[["`%voice`"]]
library(randomForest)
install.packages("randomForest")
library(randomForest)
# Fitting a random forest model
model_rf <- randomForest(total.time ~ `%copied` + `%voice`, data = cons.data)
summary(model_rf)
# Fitting a random forest model
model_rf <- randomForest(total.time ~ `%copied` + `%voice`, data = cons.data)
# Remove rows with missing values in specified columns
cons.data_clean <- na.omit(cons.data, cols = c("total.time", `%copied`, `%voice`))
# Now fit the random forest model
library(randomForest)
model_rf <- randomForest(total.time ~ `%copied` + `%voice`, data = cons.data_clean)
model_rf <- randomForest(total.time ~ cons.data_clean$`%copied` + `%voice`, data = cons.data_clean)
model_rf <- randomForest(total.time ~ cons.data_clean$`%copied` + cons.data_clean$`%voice`, data = cons.data_clean)
cons.data <- readRDS("cons_data.rds")
# Calculate the logarithm of total time
cons.data <- cons.data %>%
mutate(smart_phrases_count = str_count(smartphraseids, "\\["))  # Count "[" in smartphraseids
# Applying log transformation to the predictors
cons.data <- cons.data %>%
mutate_at(vars(`%copied`, `%voice`, smart_phrases_count, weekend, pm, notesize,
resident.time, staff.time, iteration, starttostop, sources, resident.percent),
~ log1p(.))  # log1p is used to apply log(1 + x) to avoid log(0)
# Calculate correlation matrix
correlation_matrix <- cor(selected_data, method = "pearson", use = "complete.obs")  # Handles missing values by listwise deletion
cons.data <- readRDS("cons_data.rds")
# Calculate the logarithm of total time
cons.data <- cons.data %>%
mutate(smart_phrases_count = str_count(smartphraseids, "\\["))  # Count "[" in smartphraseids
# Applying log transformation to the predictors
cons.data <- cons.data %>%
mutate_at(vars(`%copied`, `%voice`, smart_phrases_count, weekend, pm, notesize, total.time,
resident.time, staff.time, iteration, starttostop, sources, resident.percent),
~ log1p(.))  # log1p is used to apply log(1 + x) to avoid log(0)
# Select relevant columns
selected_data <- cons.data %>%
select(log_total_time, `%copied`, `%voice`, smart_phrases_count, weekend,
pm, notesize, resident.time, staff.time, iteration, starttostop,
sources, resident.percent)
# Select relevant columns
selected_data <- cons.data %>%
select(total.time, `%copied`, `%voice`, smart_phrases_count, weekend,
pm, notesize, resident.time, staff.time, iteration, starttostop,
sources, resident.percent)
# Calculate correlation matrix
correlation_matrix <- cor(selected_data, method = "pearson", use = "complete.obs")  # Handles missing values by listwise deletion
print(correlation_matrix)
View(correlation_matrix)
cons.data <- readRDS("cons_data.rds")
# Calculate the logarithm of total time
cons.data <- cons.data %>%
mutate(smart_phrases_count = str_count(smartphraseids, "\\["))  # Count "[" in smartphraseids
# Applying log transformation to the predictors
cons.data <- cons.data %>%
mutate_at(vars(`%copied`, `%voice`, smart_phrases_count, weekend, pm, notesize, total.time,
resident.time, staff.time, iteration, starttostop, sources, resident.percent),
~ log1p(.))  # log1p is used to apply log(1 + x) to avoid log(0)
# Select relevant columns
selected_data <- cons.data %>%
select(total.time, `%copied`, `%voice`, smart_phrases_count, weekend,
pm, notesize, resident.time, staff.time, iteration, starttostop,
sources, resident.percent)
# Calculate correlation matrix
correlation_matrix <- cor(selected_data, method = "pearson", use = "complete.obs")  # Handles missing values by listwise deletion
print(correlation_matrix)
# Melting the correlation matrix into a long format
melted_corr_matrix <- melt(correlation_matrix)
# Plotting the heatmap
x = ggplot(data = melted_corr_matrix, aes(x = Var1, y = Var2, fill = value)) +
geom_tile() +
geom_text(aes(label = sprintf("%.2f", value)), size = 3, color = "black") +
scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1,1)) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(angle = 0, hjust = 1)) +
labs(title = "Heatmap of Pearson Correlation with Coefficients", x = "", y = "", fill = "Correlation")
ggsave("xx.png", plot = x, width = 14, height = 12)
# Sampling a subset of the data, for example 10% of the rows
sampled_data <- selected_data[sample(nrow(selected_data), size = 0.1 * nrow(selected_data)),]
# Create matrix of scatter plots with sampled data
c = ggpairs(sampled_data,
columns = c("log_total_time", "%copied", "%voice", "smart_phrases_count", "weekend",
"pm", "notesize", "resident.time", "staff.time", "iteration", "starttostop",
"sources", "resident.percent"),
lower = list(continuous = "points"),
upper = list(continuous = "cor"),
diag = list(continuous = "barDiag"))
# Create matrix of scatter plots with sampled data
c = ggpairs(sampled_data,
columns = c("total.time", "%copied", "%voice", "smart_phrases_count", "weekend",
"pm", "notesize", "resident.time", "staff.time", "iteration", "starttostop",
"sources", "resident.percent"),
lower = list(continuous = "points"),
upper = list(continuous = "cor"),
diag = list(continuous = "barDiag"))
ggsave("cc.png", plot = c, width = 14, height = 12)
# Creating the matrix of scatter plots with slope lines in the lower triangle
c <- ggpairs(sampled_data,
columns = c("total.time", "%copied", "%voice", "smart_phrases_count", "weekend",
"pm", "notesize", "resident.time", "staff.time", "iteration", "starttostop",
"sources", "resident.percent"),
lower = list(continuous = wrap("points", colour = "blue") +
wrap("smooth", method = "lm", colour = "red", se = FALSE)),
upper = list(continuous = "cor"),
diag = list(continuous = "barDiag"))
# Creating the matrix of scatter plots with slope lines in the lower triangle
c <- ggpairs(sampled_data,
columns = c("total.time", "%copied", "%voice", "smart_phrases_count", "weekend",
"pm", "notesize", "resident.time", "staff.time", "iteration", "starttostop",
"sources", "resident.percent"),
lower = list(continuous = function(data, mapping, ...) {
ggplot(data = data, mapping = mapping) +
geom_point(color = "blue") +
geom_smooth(method = "lm", color = "red", se = FALSE)
}),
upper = list(continuous = "cor"),
diag = list(continuous = "barDiag"))
# Viewing the plot (if needed)
print(c)
# Saving the plot
ggsave("cc.png", plot = c, width = 14, height = 12)
# Creating the matrix of scatter plots with slope lines in the lower triangle
c <- ggpairs(sampled_data,
columns = c("total.time", "%copied", "%voice", "weekend", "pm", "notesize", "resident.time", "staff.time", "starttostop", "resident.percent"),
lower = list(continuous = function(data, mapping, ...) {
ggplot(data = data, mapping = mapping) +
geom_point(color = "blue") +
geom_smooth(method = "lm", color = "red", se = FALSE)
}),
upper = list(continuous = "cor"),
diag = list(continuous = "barDiag"))
# Viewing the plot (if needed)
print(c)
View(model_results)
# Saving the plot
ggsave("cc.png", plot = c, width = 14, height = 12)
View(cons.data)
#Clean environment and free memory
rm(list = ls())
gc()
setwd("C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Script")
save_path <- "C:\\Users\\yahya\\OneDrive\\Research\\residency.notes\\Script\\Script cache and figures\\Cache"
knitr::opts_chunk$set(
echo = FALSE,
warning = FALSE,
message = FALSE,
fig.width = 10,
fig.height = 8,
cache = TRUE,
cache.path = save_path,
fig.path = save_path
)
#Set number of digits to display
options(digits = 5, scipen = 999)
#Packages and Libraries
library(ggplot2)
library(tidyverse)
library(lubridate)
library(readr)
library(conflicted)
library(dplyr)
library(htmltools)
library(skimr)
library(janitor)
library(gt)
library(tidyr)
library(stringdist)
library(purrr)
library(report)
library(grid)
library(stringr)
library(gridExtra)
library(MASS)
library(knitr)
library(tools)
library(kableExtra)
library(DT)
library(broom)
library(htmlwidgets)
library(webshot)
library(extrafont)
library(ragg)
library(plotly)
library(pagedown)
library(readxl)
library(rlang)
library(nortest)
library(glue)
library(reshape2)
library(GGally)
library(boot)
conflict_prefer("select", "dplyr")
conflicts_prefer(dplyr::filter)  # Set conflict resolution preferences
cons.data <- readRDS("cons_data.rds")
# Create a new column "other.time"
cons.data <- cons.data %>%
mutate(other.time = total.time - staff.time - resident.time)
